# -*- mode:org; fill-column:79; -*-
#+title: CSV-SQLite3 Using Node
#+subtitle:Convert CSV files into data usable by SQLite3@@texinfo:@*@@
#+subtitle:{{{date}}} {{{version}}}
#+date:2019-07-20 18:03
#+macro: version Version 0.0.12

* Introduction
:PROPERTIES:
:unnumbered: t
:END:
US Bank has the facility to download bank records in CSV form.  This program is
designed to convert those downloaded CSV files into a form usable by SQLite,
and then to use SQLite to process the data.

{{{heading(Header Lines)}}}

The header lines are:

: "Date","Transaction","Name","Memo","Amount"

{{{heading(Data Columns)}}}

{{{subheading(Date)}}}

A sample date is:

: 1/4/2016

{{{subheading(Transaction)}}}

A =Transaction= is one of

- =DEBIT=
- =CREDIT=

{{{subheading(Name)}}}

A sample =name= entry is:

: DEBIT PURCHASE -VISA USPS PO BOXES 66800-3447779 DC

{{{subheading(Memo)}}}

A sample =memo= entry is:

: Download from usbank.com. USPS PO BOXES 66800-3447779 DC

{{{subheading(Amount)}}}

- -66.0000

* SQLite Tables
#+cindex:tables
The minimum SQLite tables that should be created are:

- usb :: business (6815), trust (6831), personal (6151)
- cases :: 190301, etc.
- people :: John Doe, Mary Jane, etc.
- businesses :: Law Office of ..., etc.


More can be created as needed.

** SQLite Table Columns
#+cindex:columns
The columns that should be created for the bank tables are:

- =rowid= (implicit creation)
- =date= in the form of =yyyy-mm-dd=
- =trans= containing either =CREDIT | DEBIT=
- =checkno= containing a check number, if present (=check= is a reserved word
  and throws an error)
- =txfr= containing a direction arrow (=<= or =>=) and a bank account (=usb_6151=)
- =payee=
- =category=
- =memo=
- =desc1=
- =desc2=
- =caseno= containing a related case number (=case= is apparently a reserved
  word and throws an error)
- =amount= in the form =\pm##,###.##=


| rowid       | date       | trans  | checkno | txfr       | payee    | category | memo | desc1 | desc2 | caseno  | amount     |
|-------------+------------+--------+---------+------------+----------+----------+------+-------+-------+---------+------------|
| primary key | yyyy-mm-dd | credit | ####    | < usb 6151 | text     | text     | text | text  | text  | integer | \pm##,###.## |
| implicit    | not null   | debit  | null    | > usb 6831 | not null | null     | null | null  | null  | null    | not null   |
| creation    |            |        |         | null       |          |          |      |       |       |         |            |
|-------------+------------+--------+---------+------------+----------+----------+------+-------+-------+---------+------------|

#+name: usb_table_schema
#+begin_src sql
    usb (\
           rowid    INTEGER PRIMARY KEY NOT NULL,\
           date     VARCHAR NOT NULL,\
           trans    VARCHAR NOT NULL,\
           checkno  VARCHAR,\
           txfr     VARCHAR,\
           payee    VARCHAR NOT NULL,\
           category VARCHAR,\
           memo     VARCHAR,\
           desc1    VARCHAR,\
           desc2    VARCHAR,\
           caseno   VARCHAR,\
           amount   REAL NOT NULL )
#+end_src

* Create the Project
This project's dependencies are the following Node.js modules:

- ~command-line-args~ :: https://github.com/75lb/command-line-args#readme
- ~command-line-usage~ :: https://github.com/75lb/command-line-usage
- ~csv~ :: https://csv.js.org/
- ~sqlite3~ :: https://github.com/mapbox/node-sqlite3/wiki
- ~accounting~ :: http://openexchangerates.github.io/accounting.js/

#+name:tangle-CSV-SQLite3-project
#+begin_src emacs-lisp :results output :exports results
(org-babel-tangle-file "CSV-SQLite3.org")
#+end_src

** Install the Dependencies
#+name:create-CSV-SQLite3-project
#+header: :exports both :results output
#+begin_src sh
yarn --yes init
yarn add command-line-args command-line-usage csv sqlite3 accounting
#+end_src

** Establish some Basic Dependencies
:PROPERTIES:
:header-args: :comments both
:END:
In addition to the foregoing dependencies, this project uses the following
Node.js built-in modules:

- ~fs~ :: File System for working with files

- ~util~ :: Utilities for inspectint objects

#+name:csv-sqlite3-dependencies
#+header: :mkdirp yes
#+begin_src js -n :tangle index.js
const fs   = require('fs');
const util = require('util');

const cl_args  = require('command-line-args');
const cl_usage = require('command-line-usage');
const csv      = require('csv');
const sqlite3  = require('sqlite3').verbose();      // remove 'verbose' in production
const accounting = require('accounting');
#+end_src

* Working with the Command Line
:PROPERTIES:
:header-args: :comments both
:END:
Here is implementation of command-line argument parsing and the generation of a
usage message triggered by requesting the option =--help=.

** Command Line Usage
#+cindex:command-line usage
#+cindex:usage
#+cindex:@command{command-line-usage}
This section generates a usage message activated by the =--help= option.  It
uses the [[option-defs-variable][~options_defs~]] object created in the code below.

#+name:csv-sqlite3-usage
#+begin_src js
const sections = [
    {
        header: 'CSV-SQLite',
        content: 'Processes raw usb csv files into a form usable by SQLite3'
    },
    {
        header: 'Options',
        optionList: option_defs,
    },
    {
        content: `Project directory: {underline ${process.env.WORKNODE}/CSV-SQLite3}`
    }
];
const usage = cl_usage(sections);
console.log(usage);
#+end_src

** Command Line Argument Processing
#+cindex:command-line arguments
#+cindex:arguments
#+cindex:@command{command-line-arguments}
#+cindex:@option{--help}
#+cindex:@option{--create}
#+cindex:@option{--delete}
Options include giving the name of a database to attach to using =--attach
<db>=.  In the absence of this option, a default database will be used.  A
database can be deleted here as well using the option =--delete <db>=, with a
backup being saved in the =WORKBAK= directory wtih the unix time suffixed to
the end.

Initially, the database should be creatable and deleteable.

: csvsqlite --help | -h

: csvsqlite --attach <db> | -a <db-name>

: csvsqlite --delete <db> | -d <db-name>

Also, identify the CSV file to transform via the =--csv= option:

: csvsqlite --csv | -c 6815|6831 2004...2019

<<option-defs-variable>>
#+name:csv-sqlite3-command-line-arg-processing
#+header: :noweb yes
#+begin_src js +n :tangle index.js
const option_defs = [
    { name: 'help',   alias: 'h', type: Boolean, description: 'Prints this usage message.' },
    { name: 'attach', alias: 'a', type: String,  description: 'Attach to an existing or new database file.' },
    { name: 'delete', alias: 'd', type: String,  description: 'Delete an existing database file.' },
    { name: 'csv',    alias: 'c', type: String,  description: 'Process a CSV file [6815|6831] yyyy', multiple: true  },
];
const options = cl_args(option_defs);
console.log(options);

if (options.help) {
    <<csv-sqlite3-usage>>
    process.exit(0);
}
#+end_src

* Attach To or Delete a Database
:PROPERTIES:
:header-args: :comments both
:END:
SQLite3 can have any number of databases.  Only one is initially attached, but
more can be attached subsequent to the first attachment.  If the database does
not exist, it will be created.  If the user requests that a database file be
deleted, it will be backed up first, then deleted.

The user can attach to a database file (either a specified file or the default
file, defined as ~$WORKFIN/workfin.db~), or delete a specified database file.
A deleted file is backed up to a backup directory that needs to be defined as a
shell environment variable: =WORKBAK=.

#+cindex:@file{db} database file
#+cindex:database file @file{db}
The attached database will be referenced as ~db~.

{{{heading(Verbose Mode)}}}

#+cindex:verbose mode
During development, call the ~verbose()~ method on the ~sqlite3~ object to
enable better stack traces.  In production, remove this call for improved
performance.

#+name:csv-sqlite3-create-database
#+header: :noweb yes
#+begin_src js +n :tangle index.js

  if ( !process.env.WORKDB ) {
      console.error('You must define a shell variable named WORKFDB as a base directory for the database file.');
      process.exit(1);
  }

  const WORKDB = process.env.WORKDB; // base directory for db
  const DB_DEFAULT = 'workfin.sqlite';
  const db_file = options.attach ? options.attach :    // for attaching
                  options.delete ? options.delete :    // for deletion
                  DB_DEFAULT;  	       	         // use the default name
  const db_path = `${WORKDB}/${db_file}`;

  /*---DELETE--*/
  if (options.delete) {
      if (!process.env.WORKBAK) {
          console.error('You must define a shell variable named WORKBAK as a backup directory before deleting a database file.');
          process.exit(1);
      }
      const db_path_bak = `${process.env.WORKBAK}/${db_file}.${Date.now()}`;
      fs.renameSync(db_path, db_path_bak);
      console.error(`Successfully deleted ${db_path};\nThis file has been backed up to ${db_path_bak}`);
      process.exit(0);
  }

  /*--ATTACH--*/
  const db = new sqlite3.Database(db_path, (err) => {
      if (err)
          console.error(`Error opening database file ${db_path}: ${err.message})`);
      else
          console.log(`Successfully attached to database file ${db_path}`);
  });
  db.run("CREATE TABLE IF NOT EXISTS\
      <<usb_table_schema>>"
  );

#+end_src

* Process CSV Files
:PROPERTIES:
:header-args: :comments both
:END:
The Node.js module [[https://csv.js.org/][~csv~]] contains the [[https://csv.js.org/parse/][csv parser]], [[https://csv.js.org/transform/][stream transformer]], and [[https://csv.js.org/stringify/][csv
stringifier]], all of which will be used in this project.  The pattern is to open
a CSV file, parse a CSV string into records and pipe those records through the
transformer to be massaged into shape.  From there the new data is saved in
another CSV file and also an SQLite3 database using [[https://www.npmjs.com/package/sqlite3][~sqlite3~]] (see its [[https://github.com/mapbox/node-sqlite3/wiki/API][API]]
also).

The processing of a CSV file, therefore, involves the following steps and
Node.js modules:

1. Find the correct CSV file (using ~FileSystem~) and open it as a [[https://nodejs.org/dist/latest-v12.x/docs/api/stream.html#stream_readable_streams][Readable
   Stream]];

2. Open a new CSV file to hold the new transformed data as a [[https://nodejs.org/dist/latest-v12.x/docs/api/stream.html#stream_writable_streams][Writable Stream]]

3. Open an SQLite3 database to hold the new transformed data

4. Read the CSV records from the file as a string (using ~StreamReader~)

5. Parse the string into JS records (using ~CSV-Parse~)

6. Transform the JS records into usable data (using ~CSV-Transform~)

7. Save the new data in the new CSV file (using ~StreamWriter~)

8. Save the new data in an SQLite3 database (using ~SQLite3~)

** Set Up CSV-Stringify
This section receives the transformed records from the Transform function and
writes them to new csv files.  The new csv files will be located close to the
database files, so there should be an environment variable named =WORKDB=,
pointing to, for example, ~$WORK/workfin/db~.  A file will be called, for
example, ~usb_6815__2016.csv~.  Notice that this file name uses two
underscores, whereas the source files use two dashes; in all other respects,
they are the same.

#+name:csv-stringify-function
#+begin_src js +n :tangle index.js
  const stringifier = csv.stringify({
      header: true,
      columns: [
          'date',
          'trans',
          'checkno',
          'txfr',
          'payee',
          'category',
          'memo',
          'desc1',
          'desc2',
          'caseno',
          'amount',
          'OrigPayee',
          'OrigMemo',
          ],
  });

  const acct = options.csv[0],
        year = options.csv[1];

  const csv_file = `usb_${acct}__${year}.csv`;
  const csv_path = `${process.env.WORKDB}/csv`;
  const csv_path_file = `${csv_path}/${csv_file}`;
  if (! fs.existsSync(csv_path)) {
      try {
          fs.mkdirSync(csv_path);
          console.log(`CSV FILE PATH: ${csv_path} has been created`);
      } catch (err) {
          console.error(err.message);
          process.exit(1);
      }
  }
  console.log(`CSV FILE PATH: ${csv_path} exists`);

  let csv_stringifier;
  try {
      csv_stringifier = fs.createWriteStream(csv_path_file);
      console.log(`WRITE STREAM: ${csv_path_file} has been successfully opened.`);
  } catch (err) {
      console.error(err.message);
      process.exit(1);
  }

  stringifier.on('readable', function() {
      console.log('stringifier is now readable');
      let row;
      while (row = this.read()) {
          console.log(`stringifer row: ${row}`);
          csv_stringifier.write(row);
      }
  });

  stringifier.on('error', function(err) {
      console.error(err.message);
  });

  stringifier.on('finish', function() {
      console.log('stringifier is done writing to csv_stringifer');
      csv_stringifier.end('stringifer called csv_stringifier\'s "end" method');
  });

  stringifier.on('close', function() {
      console.log('stringifier is now closed');
  });

  csv_stringifier.on('close', function() {
      console.log('csv_stringifier is now closed');
  });
#+end_src

** Set Up Stream-Transform and Transform Function
:PROPERTIES:
:header-args: :comments both
:END:
This code implements the stream transformer functionality, which is at the
heart of this project.  The stream transformer receives data via its ~write~
method, executed in the parser for every CSV record in the file, in its
~transform~ method, which contains a transform function as its first argument.
This transform function argument performs the major work of manipulating each
record.  After it transforms the data, the transformer receives the new data
via a =readable= event, where it can process the data.  In this case, the data
will be saved into the SQLite3 database.

*** Set Up the Transform Function
The Transform Function receives a record and massages it into shape.  The
following regular expressions were created based upon inspection of the raw
data as it came from the bank for years 2016, 2017, and 2018.  It does a decent
job of creating readable payees and memos, as well as txfrs (transfers), but it
has not been set up to do anything for check payees, categories or related
records, for example.

#+name:stream-transform-function
#+begin_src js +n :tangle index.js
  const transform_function = function (record) {
      const DEBIT   = 'debit';
      const CREDIT  = 'credit';
      const CHECK   = 'checkno';
      const CASH    = 'cash';
      const DEPOSIT = 'deposit';
      const UNKNOWN = 'unknown';
      const TRANS    = 'transfer';
      const USBANK  = 'usbank';
      let   trfrom  = '';

      // Add new columns: checkno, txfr, acct, _case, desc1, desc2, category
      record.checkno = null; // check no.
      record.trans    = null; // direction and acct #
      record.acct    = null; // related account foreign key
      record.caseno  = null; // related case foreign key
      record.desc1   = null; // noun
      record.desc2   = null; // adjective
      record.category= null; // categorization of the transaction

      // Format date as yyyy-mm-dd; delete original Date
      record.date = new Date(record['Date']).toISOString().split('T')[0];
      delete record['Date'];

      // Change Transaction to trans; delete original Transaction
      record.trans = record['Transaction'].toLowerCase();
      delete record['Transaction'];

      // Change Amount to amount as Currency type; delete original Amount
      record.amount = accounting.formatMoney(record['Amount']);
      delete record['Amount'];

      // Change Name to payee; keep original Name as OrigName; delete Name
      record.payee = record['Name'].toLowerCase().trimRight();
      record.OrigPayee = record['Name'];
      delete record['Name'];

      // Clean up Memo by removing Download message; return as memo; keep Memo as OrigMemo
      let re = new RegExp('Download from usbank.com.\\s*');
      record.memo = record['Memo'].replace(re,'').toLowerCase();
      record.OrigMemo = record['Memo'];
      delete record['Memo'];

      // Add check no. to checkno column
      if (record.payee === CHECK) {
          const checkno = record.trans.replace(/^0*/,'');
          record.checkno  = checkno;
          record.trans   = DEBIT;
          record.payee  = UNKNOWN;
          record.memo  += `Purchase by check no. ${checkno}`;
          record.desc1  = 'purchase';
          record.desc2  = 'check';
      }

      if (record.payee.match(/(returned) (item)/)) {
          record.desc1 = RegExp.$2;
          record.desc2 = RegExp.$1;
          record.payee = USBANK;
          record.memo = `${record.desc2} ${record.desc1}`;
      }

      if (record.payee.match(/(internet|mobile) (banking) transfer (deposit|withdrawal) (\d{4})\s*$/)) {
          record.desc1 = RegExp.$3;
          record.desc2 = RegExp.$1;
          record.trans = `${(RegExp.$3 === 'deposit') ? '<' : '>'} usb_${RegExp.$4}`;
          tofrom = (record.trans === 'debit') ? 'to' : 'from';
          record.payee = (record.trans === 'debit') ? `usb_${RegExp.$4}` : `usb_${options.csv[0]}`;
          record.memo = `${record.desc2} ${record.desc1}: ${TRANS} ${tofrom} ${record.memo}`;
      }

      if (record.payee.match(/debit (purchase)\s*-?\s*(visa)? /)) {
          record.desc1 = RegExp.$1;
          record.desc2 = RegExp.$2;
          record.payee = record.payee.replace(RegExp.lastMatch,'');
          record.memo = `${record.desc2} ${record.desc1} ${record.memo}`.trimLeft();;
      }

      // web authorized payment
      // atm|electronic|mobile check|rdc deposit|withdrawal <name>
      if (record.payee.match(/(web authorized) (pmt) |(atm|electronic|mobile)?\s*(check|rdc)?\s*(deposit|withdrawal)\s*(.*)?/)) {
          tofrom = '';
          record.desc1 = RegExp.$2 ? RegExp.$2 : RegExp.$4 ? RegExp.$4 : RegExp.$5 ? RegExp.$5 : 'undefined';
          record.desc2 = RegExp.$1 ? RegExp.$1 : RegExp.$3 ? RegExp.$3 : 'undefined';
          if (RegExp.$3 === 'atm' || RegExp.$3 === 'electronic' || RegExp.$3 === 'mobile' || RegExp.$5 === DEPOSIT) {
              record.payee = (RegExp.$5 === 'deposit') ? `usb_${options.csv[0]}` : CASH;
          } else {
              record.payee = record.payee.replace(RegExp.lastMatch,'');
          }
          if (record.memo.match(/paypal/) && record.trans === CREDIT) {
              record.trans = `< ${RegExp.lastMatch}`;
              tofrom = ' from';
          }
          record.memo = `${record.desc2} ${record.desc1}${tofrom} ${record.memo}`.trimRight();
      }

      if (record.payee.match(/(zelle instant) (pmt) (from (\w+\s\w+))\s(.*)$/)) {
          record.desc1 = RegExp.$2;
          record.desc2 = RegExp.$1;
          record.memo = `${record.desc2} ${record.desc1} ${RegExp.$3}`;
          record.payee = `usb_${options.csv[0]}`;
      }

      if (record.payee.match(/(overdraft|international) (paid|processing) (fee)/)) {
          record.desc1 = RegExp.$3;
          record.desc2 = `${RegExp.$1} ${RegExp.$2}`;
          record.payee = USBANK;
          record.memo  = `${record.desc2} ${record.desc1} to ${record.payee}`;
      }

      record.payee = record.payee.replace(/\s*portland\s{2,}or$|\s*vancouver\s{2,}wa.*$/,'');
      record.memo  = record.memo.replace(/\s*portland\s{2,}or$|\s*vancouver\s{2,}wa.*$/,'');
      record.payee = record.payee.replace(/\s\d{3}\w+\s{2,}or$/,''); // Nike Company 019Beaverton   OR
      record.memo  = record.memo.replace(/\s\d{3}\w+\s{2,}or$/,'');
      record.payee = record.payee.replace(/\s*[-\d]{5,}\s*\w{2}$/,''); // '650-4724100 CA' & '        855-576-4493WA' & '  800-3333330 MA'
      record.memo  = record.memo.replace(/\s*[-\d]{5,}\s*\w{2}$/,'');
      record.payee = record.payee.replace(/(\s\w*https)?www.*$/,''); // WWW.ATT.COM TX; UDEMY ONLINE COUHTTPSWWW.UDECA
      record.memo  = record.memo.replace(/(\s\w*https)?www.*$/,'');
      record.payee = record.payee.replace(/\s*\w+\.com\s+\w{2}$/, '');
      record.memo  = record.memo.replace( /\s*\w+\.com\s+\w{2}$/, '');
      record.payee = record.payee.replace(/aws.amazon.cWA/i,''); // serviaws.amazon.cWA
      record.memo  = record.memo.replace(/aws.amazon.cWA/i,'');
      if (record.payee.match(/(bostype \/ wes bo)(hamilton\s+on)/)) { // WES BOHAMILTON    ON
          record.payee = 'Wes Bos';
          record.memo  = record.memo.replace(RegExp.$1,'Wes Bos');
          record.memo  = record.memo.replace(RegExp.$2, '');
      }
      record.payee = record.payee.replace(/\s{2,}/g,' ');
      record.memo  = record.memo.replace(/\s{2,}/g,' ');

      /*
        'DEBIT PURCHASE -VISA SQ *PHIL        877-417-4551WA'

        You paid Phil $159 for Atreus keyboard kit and shipping

        It is for a credit card processor that goes by the brand name
        Square Up. Merchants can run credit card transactions through
        their iPhone or iPads using the Square Up services. Mine was for
        a taxi ride. https://800notes.com/Phone.aspx/1-877-417-4551
      ,*/

      record.payee = record.payee.replace(/sq/, 'square');
      record.memo  = record.memo.replace(/sq/, 'square');

      return record;
  }
#+end_src

#+RESULTS: stream-transform-function
: undefined

*** Set Up the Stream Transform
#+name:stream-transformer
#+begin_src js +n :tangle index.js
  const transformer = csv.transform(transform_function)

  transformer.on('readable', function() {
      let record;
      while ((record = transformer.read())) {
          console.log(`Transformer record:\n${util.inspect(record)}`);


          stringifier.write(record);
      }
  });

  transformer.on('error', function(err) {
      console.error(err.message);
  });

  transformer.on('finish', function() {
      console.log('Transformer finished writing records.');
  });

  transformer.on('end', function() {
      console.log('Transformer end reached.');
      stringifier.end();
  });
#+end_src

** Set Up CSV-Parse
:PROPERTIES:
:header-args: :comments both
:END:
#+cindex:@code{write} method, transformer
This section implements the csv parser.  By default, it does little other than
read a large string of data and parse it into an array of records.  By giving
it the option =columns = true=, however, the parser will use the first line as
a list of column headings, and produce an array of objects where the keys are
column names, and the values are column entries.  Each record is written to the
stream transformer using its =WRITE= method.

#+name:csv-sqlite3-csv-parse
#+header: :noweb yes
#+header: :comments link
#+begin_src js +n :tangle index.js
const parser = csv.parse({columns: true});
const records = [];

parser.on('readable', function() {
    console.log('Parser beginning to read records.');
    let record;

    /* PARSE A RECORD AND WRITE TO THE TRANSFORMER */
    while ((record = parser.read())) {
        console.log(`parser record:\n${util.inspect(record)}`);
        transformer.write(record);
    }

});

parser.on('error', function(err) {
    console.error(err.message);
});

parser.on('end', function() {
    console.log('Parser finished reading records.');
});

parser.on('finish', function () {
    console.log('Parser finished writing records.');
    console.log('Parser calling transformer end');
    transformer.end();
});
#+end_src

** Set Up StreamReader
This section implements the Stream Reader that reads the CSV file in as a large
string of data and sends it to the csv parser via the parser's ~write~ method.

CSV financial files are found in the directories =$WORKUSB_[6815|6831]/yyyy=,
where =yyyy= can be 2004--2019, and on.  Given =[6815|6831]= and a year
=[2004|2005...2019]=, the file path will be
=$WORKUSB_6815/YYYY/usb_6815--yyyy.csv=.  This code makes sure the file exists
and the user has proper permissions to read it before proceeding.

#+name:csv-sqlite3-process-csv-files
#+header: :noweb yes
#+begin_src js +n :tangle index.js
  if (options.csv) {
      const acct = options.csv[0],
            year = options.csv[1];

      if (!process.env.WORKUSB) {
          console.error('You must assign a path to the shell variable WORKUSB');
          process.exit(1);
      }

      const acct_year_path = `${process.env.WORKUSB}/usb_${acct}/${year}`;
      const acct_year_csv_file = `usb_${acct}--${year}.csv`;
      const acct_year_csv_file_path = `${acct_year_path}/${acct_year_csv_file}`;
      if (!fs.existsSync(acct_year_csv_file_path) || !(fs.accessSync(acct_year_csv_file_path, fs.constants.R_OK) === undefined)) {
          console.error(`Cannot find or access the CSV file at '${acct_year_csv_file_path}'.`);
          process.exit(1);
      }
      console.log(`Successfully found the CSV file: '${acct_year_csv_file_path}'`);

      /* CREATE THE STREAM HERE */
      const csv_file_stream = fs.createReadStream(acct_year_csv_file_path, {encoding: 'utf8'});

      /* Set up streaming events 'READABLE', 'ERROR', and 'END' */
      csv_file_stream.on('readable', function () {
          let record;

          /* READ THE RECORDS */
          while ((record = this.read())) {
              console.log(`readable record: ${record}`);

              /* WRITE A RECORD TO THE PARSER */
              parser.write(record);

          }
          parser.end();

      });

      csv_file_stream.on('error', function(err) {
          console.error(err.message);
      });

      csv_file_stream.on('end', function () {
          console.log('Reader finished reading data.');
      });
  }
#+end_src

* Create Tables

* Index
:PROPERTIES:
:unnumbered: t
:index:    cp
:END:

* Macro Definitions                                                :noexport:
#+macro: heading @@texinfo:@heading @@$1
#+macro: subheading @@texinfo:@subheading @@$1

* Export Settings                                                  :noexport:
#+texinfo_filename:csv-sqlite3.info
#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+texinfo_dir_category:CSV
#+texinfo_dir_title:ConvertCSV (convertcsv)
#+texinfo_dir_desc:Convert USB CSV files to SQLite
#+texinfo_printed_title:ConvertCSV Using Node.js CSV-Parser

* Local Variables                                                  :noexport:
# Local Variables:
# time-stamp-pattern:"8/^\\#\\+date:%:y-%02m-%02d %02H:%02M$"
# End:
